# 1. _Name a real-world example of an existing AI system that is problematic in that it actually enacts existing problematic social systems/practices_

A problematic algorithm that reinforces existing social issues is Facebook's utilization of A.I. to increase user engagement on their platforms. While the algorithm's intention is not to endorse violence or bad behavior, it frequently gives rise to unintended consequences that adversely impact numerous users. For instance, amid the COVID-19 pandemic, the widespread dissemination of false information on Facebook caused significant concern, as the inherently inaccurate news had the potential to lead individuals misinformed, fostering harmful beliefs such as racial bias against Asian individuals.

# 2. _Describe this system in terms of (your perceived high-level) **goals**,**environment**, and **adaptations** of the system._

**Goals**    
    The goal of the Facebook's AI system is to attract as many people as possible to use the Facebook App so that they would create more profit and provide user a news that they are interested in.    
**Environment**      
    The environment in which Facebook's AI system is in is a complex and dynamic one. There is a wide variety of users and contents, and these are constantly interacting and affecting each other. Users interact with each other by liking, commenting, and sharing posts. They can also create their own posts, which can be news articles, photos, videos, or anything else.         
**Adaptations**     
    The Facebook AI system adapts to its environment by analyzing millions of user data and behavioral patterns to learn what each user likes and the preferences of the masses. It then recommends posts or news that would satisfy most of the users on its apps. The inner environment of the system changes as the system gathers more information and makes changes to its algorithms. As the system makes changes, it could reinforce certain types of content and can cause some unintended consequences.        

# 3. _Describe a potential reimagined system in terms of **goals**,**environment**, and **adaptations**. How does it improve upon the system described in 2?_

**Goals**    
   The reimagined system would prioritize user well-being and mental health by reducing the spread of misinformation and divisive content. This is a significant improvement over the original system, which did not take into account the negative impact of misinformation on users' mental health. 
   The new system would use a variety of methods to reduce the spread of misinformation, such as fact-checking, labeling of false content, and limiting the reach of harmful content. It would also promote positive and uplifting content that would help to improve users' mental health.         
**Environment**      
    In the reimagined system, the environment still includes the vast user base with their diverse interactions like liking, commenting, and sharing. However, added to this environment are verified third-party fact-checkers and mental health professionals. The feedback from these contributes to better contents in this platform. An emphasis on community guidelines and standards that prioritize truthfulness and mental well-being would create a more informed and healthier environment for users.    
**Adaptations**     
    The reimagined system would adapt to its enviornment by constantly monitoring the accuracy and impact of the content towards the user on the platform. If the system detects patterns of mininformation by various methods, the system would adjust its recommendation algorithms to limit the spread of such content. Also, it would prioritize content that has been verified as accurate or promotes positive community values. The system would also take user feedback more seriously, allowing users to question or challenge content they find misleading or harmful. With these adaptations, the AI system becomes more accountable, transparent, and responsive to the needs and well-being of its user base, fostering an environment of trust and positivity.        